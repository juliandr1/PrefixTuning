{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import transformers"
      ],
      "metadata": {
        "id": "TW9zmjhntLYS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 759
        },
        "id": "OqZseOrDdqO0",
        "outputId": "c08d7e5a-06a3-474c-8495-b7eefa96bdec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: transformers 4.40.1\n",
            "Uninstalling transformers-4.40.1:\n",
            "  Would remove:\n",
            "    /usr/local/bin/transformers-cli\n",
            "    /usr/local/lib/python3.10/dist-packages/transformers-4.40.1.dist-info/*\n",
            "    /usr/local/lib/python3.10/dist-packages/transformers/*\n",
            "Proceed (Y/n)? Y\n",
            "  Successfully uninstalled transformers-4.40.1\n",
            "Obtaining file:///content/drive/MyDrive/transformers\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Checking if build backend supports build_editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing editable metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from transformers==3.2.0) (1.25.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from transformers==3.2.0) (24.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers==3.2.0) (3.13.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers==3.2.0) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers==3.2.0) (4.66.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers==3.2.0) (2023.12.25)\n",
            "Requirement already satisfied: sentencepiece!=0.1.92 in /usr/local/lib/python3.10/dist-packages (from transformers==3.2.0) (0.1.99)\n",
            "Collecting sacremoses (from transformers==3.2.0)\n",
            "  Downloading sacremoses-0.1.1-py3-none-any.whl (897 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m897.5/897.5 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==3.2.0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==3.2.0) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==3.2.0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==3.2.0) (2024.2.2)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from sacremoses->transformers==3.2.0) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from sacremoses->transformers==3.2.0) (1.4.0)\n",
            "Building wheels for collected packages: transformers\n",
            "  Building editable for transformers (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for transformers: filename=transformers-3.2.0-0.editable-py3-none-any.whl size=15625 sha256=bac24c5d47f5347ab22735ded88d2c7554bf3e2c3e5452689ae0c94afaed943c\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-mjfqa2rm/wheels/c4/5a/fe/c643984a08f166b105b12d0903475da42b7a23160c6d9ca879\n",
            "Successfully built transformers\n",
            "Installing collected packages: sacremoses, transformers\n",
            "Successfully installed sacremoses-0.1.1 transformers-3.2.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "transformers"
                ]
              },
              "id": "0f2b17962ade4bdc969843d1a92cc30c"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Install desired version of transformers\n",
        "!pip uninstall transformers\n",
        "!pip install -e /content/drive/MyDrive/transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0psZkcjrknYg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "09d61dd8-6a14-45be-f7e6-998b39784dec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: unidecode in /usr/local/lib/python3.10/dist-packages (1.3.8)\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import T5Tokenizer\n",
        "\n",
        "!pip install unidecode"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l93fR0nBdu6y"
      },
      "outputs": [],
      "source": [
        "import torch.nn.init as init\n",
        "class PrefixTuning(nn.Module):\n",
        "\n",
        "    def __init__(self, pretrained_config, prompt_len=48, hidden_dim = 800):\n",
        "\n",
        "        super().__init__()\n",
        "\n",
        "        self.match_n_layer = pretrained_config.num_layers\n",
        "        self.match_n_head = pretrained_config.num_heads\n",
        "        self.n_embd = pretrained_config.d_model\n",
        "        self.match_n_embd = self.n_embd // self.match_n_head\n",
        "\n",
        "        # Config of Pre-Trained LM\n",
        "        # torch.tensor([0, 1, 2, .. , prefix_len-1])\n",
        "        self.pretrained_config = pretrained_config\n",
        "        self.pre_prompt = torch.arange(prompt_len)\n",
        "\n",
        "        # Embedding\n",
        "        self.wte = nn.Embedding(num_embeddings=prompt_len, embedding_dim=self.n_embd)\n",
        "        # Reparameterization\n",
        "        self.control_trans = nn.Sequential(\n",
        "            nn.Linear(self.n_embd, hidden_dim),\n",
        "            nn.Tanh(),\n",
        "            nn.Linear(hidden_dim, hidden_dim),\n",
        "            nn.Tanh(),\n",
        "            nn.Linear(hidden_dim, 2 * self.match_n_layer * self.n_embd)\n",
        "        )\n",
        "\n",
        "\n",
        "        self.wte2 = nn.Embedding(num_embeddings=prompt_len, embedding_dim=self.n_embd)\n",
        "        # Reparameterization\n",
        "        self.control_trans2 = nn.Sequential(\n",
        "            nn.Linear(self.n_embd, hidden_dim),\n",
        "            nn.Tanh(),\n",
        "            nn.Linear(hidden_dim, hidden_dim),\n",
        "            nn.Tanh(),\n",
        "            nn.Linear(hidden_dim, 2 * self.match_n_layer * self.n_embd)\n",
        "        )\n",
        "\n",
        "\n",
        "        self.wte_enc = nn.Embedding(prompt_len, self.n_embd)\n",
        "        self.control_trans_enc = nn.Sequential(\n",
        "                        nn.Linear(self.n_embd, hidden_dim),\n",
        "                        nn.Tanh(),\n",
        "                        nn.Linear(hidden_dim, hidden_dim),\n",
        "                        nn.Tanh(),\n",
        "                        nn.Linear(hidden_dim, self.match_n_layer * 2 * self.n_embd))\n",
        "\n",
        "        self.prompt_len = prompt_len\n",
        "        self.dropout = nn.Dropout(0.1)\n",
        "\n",
        "    def forward(self, batch_size, device, sample_size = 1):\n",
        "        # Shape: batch_size, prompt_len\n",
        "        input_tokens = self.pre_prompt.unsqueeze(0).expand(batch_size, -1).to(device)\n",
        "        # Shape: batch_size, prompt_len, d_model\n",
        "        temp_control = self.wte(input_tokens)\n",
        "        # Shape: batch_size, prompt_len, d_model\n",
        "        past_key_values = self.control_trans(temp_control)\n",
        "\n",
        "\n",
        "        temp_control2 = self.wte2(input_tokens)\n",
        "        past_key_values2 = self.control_trans2(temp_control2)  # bsz, seqlen, layer*emb\n",
        "\n",
        "        temp_control_enc = self.wte_enc(input_tokens)\n",
        "        past_key_values_enc = self.control_trans_enc(temp_control_enc)  # bsz, seqlen, layer*emb\n",
        "\n",
        "\n",
        "        if sample_size > 1:\n",
        "            past_key_values = torch.cat(sample_size * [past_key_values])\n",
        "\n",
        "        bsz, seqlen, _ = past_key_values.shape\n",
        "        past_key_values = past_key_values.view(bsz, seqlen, self.match_n_layer * 2, self.match_n_head,\n",
        "                                               self.match_n_embd)\n",
        "        past_key_values = self.dropout(past_key_values)\n",
        "        past_key_values = past_key_values.permute([2, 0, 3, 1, 4]).split(2)\n",
        "\n",
        "        if sample_size > 1:\n",
        "            past_key_values2 = torch.cat(sample_size * [past_key_values2])\n",
        "\n",
        "        past_key_values2 = past_key_values2.view(bsz, seqlen, self.match_n_layer * 2, self.match_n_head,\n",
        "                                                   self.match_n_embd)\n",
        "        past_key_values2 = self.dropout(past_key_values2)\n",
        "        past_key_values2 = past_key_values2.permute([2, 0, 3, 1, 4]).split(2)\n",
        "\n",
        "\n",
        "        bsz_enc, seqlen, _ = past_key_values_enc.shape\n",
        "        past_key_values_enc = past_key_values_enc.view(bsz_enc, seqlen, self.match_n_layer * 2, self.match_n_head,\n",
        "                                                     self.match_n_embd)\n",
        "        past_key_values_enc = self.dropout(past_key_values_enc)\n",
        "        past_key_values_enc = past_key_values_enc.permute([2, 0, 3, 1, 4]).split(2)\n",
        "\n",
        "        result = []\n",
        "        for i, key_val in enumerate(past_key_values):\n",
        "            temp_dict = {'self': {\"prev_key\": key_val[0].contiguous(),\n",
        "                                  \"prev_value\": key_val[1].contiguous()\n",
        "                                 },\n",
        "                        }\n",
        "            key_val2 = past_key_values2[i]\n",
        "            temp_dict['encoder_decoder'] = {\"prev_key\": key_val2[0].contiguous(),\n",
        "                                                \"prev_value\": key_val2[1].contiguous()\n",
        "                                                }\n",
        "            key_val_enc = past_key_values_enc[i]\n",
        "            temp_dict['encoder'] = {\"prev_key\": key_val_enc[0].contiguous(),\n",
        "                                        \"prev_value\": key_val_enc[1].contiguous()\n",
        "                                        }\n",
        "            result.append(temp_dict)\n",
        "\n",
        "        return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o_LLg309dxdR"
      },
      "outputs": [],
      "source": [
        "import copy\n",
        "class LineByLineData2TextTextDataset(Dataset):\n",
        "    \"\"\"\n",
        "    This will be superseded by a framework-agnostic approach\n",
        "    soon.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, tokenizer: T5Tokenizer, file_path: str, block_size: int, eos_tok:str):\n",
        "\n",
        "        with open(file_path, encoding=\"utf-8\") as f:\n",
        "            lines = [line.split('||') for line in f.read().splitlines() if (len(line) > 0 and not line.isspace()\n",
        "                                                                             and len(line.split('||')) ==2 )]\n",
        "        src_lines, tgt_lines = list(zip(*lines))\n",
        "        src_lines = list(src_lines)\n",
        "        tgt_lines = list(tgt_lines)\n",
        "\n",
        "        srcs = []\n",
        "        tgts = []\n",
        "\n",
        "        for src, tgt in zip(src_lines, tgt_lines):\n",
        "            input = '{} {}'.format(src, eos_tok)\n",
        "            target = '{} {}'.format(tgt, eos_tok)\n",
        "            srcs.append(input)\n",
        "            tgts.append(target)\n",
        "\n",
        "\n",
        "        batch_encoding_src = tokenizer(srcs, is_split_into_words=False)\n",
        "        batch_encoding_tgt = tokenizer(tgts, is_split_into_words=False)\n",
        "\n",
        "        self.srcs = batch_encoding_src[\"input_ids\"]\n",
        "        self.labels = batch_encoding_tgt[\"input_ids\"]\n",
        "\n",
        "        self.tokenizer = tokenizer\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.srcs)\n",
        "\n",
        "    # def __getitem__(self, i) -> torch.Tensor:\n",
        "    def __getitem__(self, i):\n",
        "        return self.srcs[i], self.labels[i]\n",
        "\n",
        "    def collate_fn(self, batch):\n",
        "      max_len_data=0\n",
        "      max_len_label=0\n",
        "      for description, target in batch:\n",
        "          if len(description)>max_len_data: max_len_data=len(description)\n",
        "          if len(target)>max_len_label: max_len_label=len(target)\n",
        "\n",
        "      attn_masks=[]\n",
        "      targets=[]\n",
        "      descriptions=[]\n",
        "\n",
        "      for description, target in batch:\n",
        "          description.extend([self.tokenizer.pad_token_id]*(max_len_data-len(description)))\n",
        "          descriptions.append(description)\n",
        "\n",
        "          attn_mask=[int(e!=self.tokenizer.pad_token_id) for e in description]\n",
        "          attn_masks.append(attn_mask)\n",
        "\n",
        "          target.extend([-100]*(max_len_label-len(target)))\n",
        "          targets.append(target)\n",
        "\n",
        "      return torch.LongTensor(descriptions), torch.LongTensor(attn_masks), torch.LongTensor(targets)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uqlB5Y9pM9Kj"
      },
      "outputs": [],
      "source": [
        "def read_e2e_files(path, tokenizer):\n",
        "    file_dict = {}\n",
        "\n",
        "    with open(path, 'r') as f:\n",
        "        for line in f:\n",
        "            src, tgt = line.strip().split('||')\n",
        "            if src not in file_dict:\n",
        "                file_dict[src] = []\n",
        "            print()\n",
        "            file_dict[src].append(tgt)\n",
        "    return file_dict\n",
        "\n",
        "def write_e2e_corr(prompt_lst, file_dict, corr_path):\n",
        "    print(len(prompt_lst))\n",
        "    with open(corr_path, 'w') as f:\n",
        "        for x in prompt_lst:\n",
        "            for line in file_dict[x]:\n",
        "                if not line.strip():\n",
        "                    print('PROBLEM', line,'PROBLEM',file_dict[x] )\n",
        "                else:\n",
        "                    print(line, file=f)\n",
        "            print('', file=f)\n",
        "\n",
        "def write_e2e_src(prompt_lst, corr_path):\n",
        "    with open(corr_path, 'w') as f:\n",
        "        for x in prompt_lst:\n",
        "            print(x, file=f)\n",
        "    return"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def freeze_params(model: nn.Module):\n",
        "    \"\"\"Set requires_grad=False for each of model.parameters()\"\"\"\n",
        "    for par in model.parameters():\n",
        "        par.requires_grad = False"
      ],
      "metadata": {
        "id": "CdfNFWFYQO_D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IEJscyQ4e7El",
        "outputId": "95c41bd4-f288-409c-85cc-baa0e7c58a3c"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Init the T5ForConditionalGeneration Model with config.use_prefix=True, config.preseqlen=5\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/transformers/src/transformers/optimization.py:503: UserWarning: This overload of add_ is deprecated:\n",
            "\tadd_(Number alpha, Tensor other)\n",
            "Consider using one of the following signatures instead:\n",
            "\tadd_(Tensor other, *, Number alpha) (Triggered internally at ../torch/csrc/utils/python_arg_parser.cpp:1630.)\n",
            "  exp_avg_sq_row.mul_(beta2t).add_(1.0 - beta2t, update.mean(dim=-1))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0 loss: 1.161553771724234\n",
            "Epoch 1 loss: 1.00836163456001\n",
            "Epoch 2 loss: 0.9848511714324875\n",
            "Epoch 3 loss: 0.970779952700195\n",
            "494\n",
            "Running MS-COCO evaluator...\n",
            "creating index...\n",
            "index created!\n",
            "Loading and preparing results...     \n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "tokenization...\n",
            "PTBTokenizer tokenized 121004 tokens at 595901.65 tokens per second.\n",
            "PTBTokenizer tokenized 14412 tokens at 130949.63 tokens per second.\n",
            "setting up scorers...\n",
            "computing METEOR score...\n",
            "METEOR: 0.487\n",
            "computing Rouge score...\n",
            "ROUGE_L: 0.748\n",
            "computing CIDEr score...\n",
            "CIDEr: 2.518\n",
            "Running Py-MTEval metrics...\n",
            "Epoch 4 loss: 0.9602026917606249\n",
            "Epoch 5 loss: 0.9520102148495007\n",
            "Epoch 6 loss: 0.9448587456951665\n",
            "465\n",
            "Running MS-COCO evaluator...\n",
            "creating index...\n",
            "index created!\n",
            "Loading and preparing results...     \n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "tokenization...\n",
            "PTBTokenizer tokenized 121004 tokens at 566953.92 tokens per second.\n",
            "PTBTokenizer tokenized 13676 tokens at 124351.87 tokens per second.\n",
            "setting up scorers...\n",
            "computing METEOR score...\n",
            "METEOR: 0.498\n",
            "computing Rouge score...\n",
            "ROUGE_L: 0.765\n",
            "computing CIDEr score...\n",
            "CIDEr: 2.580\n",
            "Running Py-MTEval metrics...\n",
            "Epoch 7 loss: 0.9391426325205686\n",
            "Epoch 8 loss: 0.9335608218043677\n",
            "Epoch 9 loss: 0.9286754110594021\n",
            "472\n",
            "Running MS-COCO evaluator...\n",
            "creating index...\n",
            "index created!\n",
            "Loading and preparing results...     \n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "tokenization...\n",
            "PTBTokenizer tokenized 121004 tokens at 523451.55 tokens per second.\n",
            "PTBTokenizer tokenized 13870 tokens at 99706.37 tokens per second.\n",
            "setting up scorers...\n",
            "computing METEOR score...\n",
            "METEOR: 0.502\n",
            "computing Rouge score...\n",
            "ROUGE_L: 0.770\n",
            "computing CIDEr score...\n",
            "CIDEr: 2.612\n",
            "Running Py-MTEval metrics...\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "import yaml\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "from pathlib import Path\n",
        "from transformers.configuration_t5 import T5Config\n",
        "from transformers import Adafactor, get_linear_schedule_with_warmup\n",
        "from transformers.modeling_t5 import T5ForConditionalGeneration\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "torch.manual_seed(101)\n",
        "\n",
        "prefix_size = 5\n",
        "batch_size = 5\n",
        "learning_rate = 5e-5\n",
        "epochs = 10\n",
        "gradient_accumulation_steps = 1\n",
        "\n",
        "\n",
        "config = T5Config.from_pretrained('t5-base')\n",
        "config.use_prefix = True\n",
        "config.preseqlen = prefix_size\n",
        "\n",
        "    # Pre-Trained T5 Tokenizer\n",
        "tokenizer = T5Tokenizer.from_pretrained('t5-base')\n",
        "tokenizer.max_length = 512\n",
        "\n",
        "\n",
        "    # Pre-Trained T5 Model\n",
        "model = T5ForConditionalGeneration.from_pretrained('t5-base', config=config).to(device)\n",
        "model.resize_token_embeddings(len(tokenizer))\n",
        "\n",
        "freeze_params(model.shared)\n",
        "for d in [model.encoder, model.decoder]:\n",
        "      freeze_params(d.embed_tokens)\n",
        "\n",
        "prefix_model = PrefixTuning(model.config, prefix_size).to(device)\n",
        "\n",
        "    # Initialize datasets and dataloaders\n",
        "dataset_train = LineByLineData2TextTextDataset(\n",
        "        tokenizer,\n",
        "        \"/content/drive/MyDrive/E2E/src1_train.txt\",\n",
        "        tokenizer.max_length,\n",
        "        tokenizer.eos_token)\n",
        "dataset_eval = LineByLineData2TextTextDataset(\n",
        "        tokenizer,\n",
        "        \"/content/drive/MyDrive/E2E/src1_valid.txt\",\n",
        "        tokenizer.max_length,\n",
        "        tokenizer.eos_token)\n",
        "\n",
        "dataloader_train = DataLoader(dataset_train, batch_size= batch_size, shuffle=True, collate_fn=dataset_train.collate_fn)\n",
        "dataloader_eval = DataLoader(dataset_eval, batch_size= batch_size, shuffle=False, collate_fn=dataset_eval.collate_fn)\n",
        "\n",
        "optimizer = Adafactor(prefix_model.parameters(),\n",
        "                      lr=learning_rate,\n",
        "                      scale_parameter=False,\n",
        "                      relative_step=False)\n",
        "\n",
        "total_training_steps = epochs * len(dataloader_train)\n",
        "\n",
        "scheduler = get_linear_schedule_with_warmup(\n",
        "    optimizer=optimizer,\n",
        "    num_warmup_steps=2000,\n",
        "    num_training_steps=total_training_steps,\n",
        ")\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  prefix_model.train()\n",
        "  epoch_loss = 0\n",
        "  for step, (data, attention_mask, target) in enumerate(dataloader_train):\n",
        "\n",
        "      data = data.to(device)\n",
        "      attention_mask = attention_mask.to(device)\n",
        "      target = target.to(device)\n",
        "\n",
        "      prefix = prefix_model(batch_size=data.shape[0], device=device)\n",
        "      outputs = model(input_ids=data, attention_mask=attention_mask, labels=target, past_key_values=prefix, use_cache = False, use_prefix  = True)\n",
        "\n",
        "      loss = outputs[0]\n",
        "\n",
        "      if (step + 1) % gradient_accumulation_steps == 0:\n",
        "        loss.backward()\n",
        "\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        prefix_model.zero_grad()\n",
        "\n",
        "      epoch_loss += loss.item()\n",
        "\n",
        "  print(\"Epoch \" + str(epoch) + \" loss: \" + str(epoch_loss/len(dataloader_train)))\n",
        "\n",
        "  # Evaluate on entire validation set after an epoch of training\n",
        "  if epoch % 1 == 0:\n",
        "    with torch.no_grad():\n",
        "      prefix_model.eval()\n",
        "\n",
        "      file_dict = {}\n",
        "\n",
        "      for step, (data, attention_mask, target) in enumerate(dataloader_eval):\n",
        "        data = data.to(device)\n",
        "        attention_mask = attention_mask.to(device)\n",
        "        target = target.to(device)\n",
        "\n",
        "        prefix = prefix_model(batch_size=data.shape[0], device=device, sample_size = 5)\n",
        "        outputs = model.generate(input_ids = data, attention_mask=attention_mask, num_beams=5, max_length = 384, past_key_values = prefix, use_prefix = True, use_cache = True)\n",
        "        output_text = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
        "\n",
        "        filtered_tensor = torch.where(target == -100, torch.tensor(0, device=device), target)\n",
        "        ground_truth = tokenizer.batch_decode(filtered_tensor, skip_special_tokens=True)\n",
        "\n",
        "        for i in range(len(output_text)):\n",
        "          if output_text[i] not in file_dict:\n",
        "            file_dict[output_text[i]] = []\n",
        "          file_dict[output_text[i]].append(ground_truth[i])\n",
        "\n",
        "      ref_file = f'/content/drive/MyDrive/E2E/eval/gold/base/prefix_dataset{\"base\"}_model_{\"base\"}_lr{learning_rate}_prefixlen{prefix_size}_epoch{epoch}.txt'\n",
        "      pred_file = f'/content/drive/MyDrive/E2E/eval/src/base/prefix_dataset{\"base\"}_model_{\"base\"}_lr{learning_rate}_prefixlen{prefix_size}_epoch{epoch}.txt'\n",
        "      results_file = f'/content/drive/MyDrive/E2E/eval/metrics/base/prefix_dataset{\"e2e\"}_model_{\"base\"}_lr{learning_rate}_prefixlen{prefix_size}_epoch{epoch}.txt'\n",
        "\n",
        "      write_e2e_corr(list(file_dict.keys()), file_dict, ref_file)\n",
        "      write_e2e_src(list(file_dict.keys()), pred_file)\n",
        "      !python /content/drive/MyDrive/E2E/e2e-metrics/measure_scores.py {ref_file} {pred_file} -p  -t -H >> {results_file}\n",
        "\n",
        "      model_name = f'/content/drive/MyDrive/E2E/models/base/prefix_dataset{\"e2e\"}_model_{\"base\"}_lr{learning_rate}_prefixlen{prefix_size}_epoch{epoch}best.pt'\n",
        "      torch.save(prefix_model.state_dict(), model_name)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/drive/MyDrive/E2E/e2e-metrics/measure_scores.py {ref_file} {pred_file} -p  -t -H >> {results_file}"
      ],
      "metadata": {
        "id": "nF9HRjo3DaHf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P5gsjf_OifyW",
        "outputId": "fed0b9e2-c353-4910-ba1f-dedc057796ac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Init the T5ForConditionalGeneration Model with config.use_prefix=True, config.preseqlen=5\n",
            "576\n",
            "Running MS-COCO evaluator...\n",
            "creating index...\n",
            "index created!\n",
            "Loading and preparing results...     \n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "tokenization...\n",
            "PTBTokenizer tokenized 132563 tokens at 627841.78 tokens per second.\n",
            "PTBTokenizer tokenized 16742 tokens at 145886.48 tokens per second.\n",
            "setting up scorers...\n",
            "computing METEOR score...\n",
            "METEOR: 0.465\n",
            "computing Rouge score...\n",
            "ROUGE_L: 0.705\n",
            "computing CIDEr score...\n",
            "CIDEr: 2.462\n",
            "Running Py-MTEval metrics...\n"
          ]
        }
      ],
      "source": [
        "from transformers.configuration_t5 import T5Config\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "prefix_size = 5\n",
        "batch_size = 5\n",
        "learning_rate = 5e-5\n",
        "epochs = 10\n",
        "gradient_accumulation_steps = 1\n",
        "\n",
        "\n",
        "config = T5Config.from_pretrained('t5-base')\n",
        "config.use_prefix = True\n",
        "config.preseqlen = prefix_size\n",
        "\n",
        "    # Pre-Trained T5 Tokenizer\n",
        "tokenizer = T5Tokenizer.from_pretrained('t5-base')\n",
        "tokenizer.max_length = 512\n",
        "\n",
        "\n",
        "    # Pre-Trained T5 Model\n",
        "model = T5ForConditionalGeneration.from_pretrained('t5-base', config=config).to(device)\n",
        "model.resize_token_embeddings(len(tokenizer))\n",
        "\n",
        "freeze_params(model.shared)\n",
        "for d in [model.encoder, model.decoder]:\n",
        "      freeze_params(d.embed_tokens)\n",
        "\n",
        "prefix_model = PrefixTuning(model.config, prefix_size).to(device)\n",
        "prefix_model.load_state_dict(torch.load(\"/content/drive/MyDrive/E2E/models/base/HAprefix_datasete2e_model_base_lr5e-05_prefixlen5_epoch9best.pt\"))\n",
        "prefix_model.eval()\n",
        "\n",
        "dataset_test = LineByLineData2TextTextDataset(\n",
        "        tokenizer,\n",
        "        \"/content/drive/MyDrive/E2E/src1_test.txt\",\n",
        "        tokenizer.max_length,\n",
        "        tokenizer.eos_token)\n",
        "dataloader_test = DataLoader(dataset_test, batch_size= batch_size, shuffle=True, collate_fn=dataset_test.collate_fn)\n",
        "\n",
        "with torch.no_grad():\n",
        "    prefix_model.eval()\n",
        "    file_dict = {}\n",
        "\n",
        "    for step, (data, attention_mask, target) in enumerate(dataloader_test):\n",
        "      data = data.to(device)\n",
        "      attention_mask = attention_mask.to(device)\n",
        "      target = target.to(device)\n",
        "\n",
        "      prefix = prefix_model(batch_size=data.shape[0], device=device, sample_size = 5)\n",
        "      outputs = model.generate(input_ids = data, attention_mask=attention_mask, num_beams=5, max_length = 384, past_key_values = prefix, use_prefix = True, use_cache = True)\n",
        "      output_text = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
        "\n",
        "      filtered_tensor = torch.where(target == -100, torch.tensor(0, device=device), target)\n",
        "      ground_truth = tokenizer.batch_decode(filtered_tensor, skip_special_tokens=True)\n",
        "      for i in range(len(output_text)):\n",
        "        if output_text[i] not in file_dict:\n",
        "          file_dict[output_text[i]] = []\n",
        "        file_dict[output_text[i]].append(ground_truth[i])\n",
        "\n",
        "    ref_file = f'/content/drive/MyDrive/E2E/eval/gold/base/prefix_dataset{\"e2e\"}_lr{learning_rate}_prefixlen{prefix_size}_test.txt'\n",
        "    pred_file = f'/content/drive/MyDrive/E2E/eval/src/base/prefix_dataset{\"e2e\"}_lr{learning_rate}_prefixlen{prefix_size}_test.txt'\n",
        "    results_file = f'/content/drive/MyDrive/E2E/eval/metrics/base/5prefix_dataset{\"e2e\"}_lr{learning_rate}_prefixlen{prefix_size}_test.txt'\n",
        "\n",
        "    write_e2e_corr(list(file_dict.keys()), file_dict, ref_file)\n",
        "    write_e2e_src(list(file_dict.keys()), pred_file)\n",
        "    !python /content/drive/MyDrive/E2E/e2e-metrics/measure_scores.py {ref_file} {pred_file} -p  -t -H >> {results_file}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RQEqyACLmTOQ"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "gpuType": "L4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}